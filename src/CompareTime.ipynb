{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Convolution\n",
      "Time seq: \t2.4659945964813232\n",
      "Time seq pure: \t4.693268299102783\n",
      "Time jit decorate: \t0.8702709674835205\n",
      "time cuda.jit decorate: \t1.7392609119415283\n",
      "Error output - output_paral:\t0.0\n",
      "Error output - out_seq:\t0.0\n",
      "Error output - output_paral_jit:\t0.0\n",
      "(64, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import cuda, jit\n",
    "import time\n",
    "import math\n",
    "from Maxpool import Maxpool, forward_paralle, forward_sequential, forward_sequence_pure\n",
    "from Convolution import Convolution, forward, forward_seq, CNN_forward\n",
    "from size import Shape\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "time_run = pd.DataFrame(columns=['seq_pure','seq_lib', 'jit', 'cuda.jit'])\n",
    "error = pd.DataFrame(columns=['seq_pure','seq_lib', 'jit', 'cuda.jit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 32\n",
    "w = 128\n",
    "a = np.random.randint(0, 256 ,(64, w * h)) \n",
    "a_size = Shape(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006002902984619141\n"
     ]
    }
   ],
   "source": [
    "maxpool = Maxpool(64,Shape(2,2))\n",
    "s_start = time.time()\n",
    "output_seq, shape_out = maxpool.forward_sequential(a, a_size)\n",
    "s_end = time.time()\n",
    "print(f'{s_end - s_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_run.loc['maxpool','seq_lib'] = s_end - s_start\n",
    "error.loc['maxpool','seq_lib'] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = (16, 16)\n",
    "# print(f'({shape_out.h // block_size[0] + 1}, {shape_out.w // block_size[1] + 1})')\n",
    "# grid_h, grid_w = shape_out.h // block_size[0] + 1,shape_out.w // block_size[1] + 1\n",
    "# grid_size = (grid_h, grid_w)\n",
    "grid_size = (math.ceil(shape_out[0] / block_size[0]),\n",
    "             math.ceil(shape_out[1] / block_size[1]))\n",
    "# print(grid_size)\n",
    "d_a = cuda.to_device(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2782268524169922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "output_jit = np.empty((maxpool.numKernel, shape_out[0]*shape_out[1]), dtype=float)\n",
    "start = time.time()\n",
    "forward_paralle[grid_size, block_size](d_a, (h, w), output_jit, (shape_out[0], shape_out[1]), (2,2), 1)\n",
    "end = time.time()\n",
    "print(f'{end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_run.loc['maxpool','jit'] = end - start\n",
    "error.loc['maxpool','jit'] = np.sum(abs(output_jit - output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003002643585205078\n"
     ]
    }
   ],
   "source": [
    "out_pure = np.empty((maxpool.numKernel, shape_out[0]*shape_out[1]), dtype=float)\n",
    "start = time.time()\n",
    "forward_sequence_pure(a, (h, w), out_pure, (shape_out[0], shape_out[1]), (2,2), 1)\n",
    "end = time.time()\n",
    "print(f'{end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_run.loc['maxpool','seq_pure'] = end - start\n",
    "error.loc['maxpool','seq_pure'] = np.sum(abs(out_pure - output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002001523971557617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_paral = np.empty((maxpool.numKernel, shape_out[0]*shape_out[1]), dtype=float)\n",
    "start = time.time()\n",
    "forward_paralle[grid_size, block_size](d_a, (h, w), output_paral, (shape_out[0], shape_out[1]), (2,2), 64)\n",
    "end = time.time()\n",
    "print(f'{end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_run.loc['maxpool', 'cuda.jit'] = end - start\n",
    "error.loc['maxpool', 'cuda.jit'] = np.sum(abs(output_paral- output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_pure</th>\n",
       "      <th>seq_lib</th>\n",
       "      <th>jit</th>\n",
       "      <th>cuda.jit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpool</th>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.278227</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         seq_pure   seq_lib       jit  cuda.jit\n",
       "maxpool  0.003003  0.006003  0.278227  0.002002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_pure</th>\n",
       "      <th>seq_lib</th>\n",
       "      <th>jit</th>\n",
       "      <th>cuda.jit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        seq_pure seq_lib  jit cuda.jit\n",
       "maxpool      0.0       -  0.0      0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeKernel = Shape(3,3)\n",
    "cnn = Convolution(64,sizeKernel)\n",
    "aAddPaddinf = cnn.addPadding(a[:1], (h, w), 1)\n",
    "w_add = w + cnn.padding*2\n",
    "h_add = h + cnn.padding*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_start = time.time()\n",
    "output = cnn.forward(aAddPaddinf, (h,w), 1, \"relu\")\n",
    "s_end = time.time()\n",
    "time_run.loc['Convolution','seq_lib'] = s_end - s_start\n",
    "error.loc['Convolution','seq_lib'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_seq = np.empty((cnn.numKernel, h*w), dtype=float)\n",
    "\n",
    "seq_start = time.time()\n",
    "#CNN_forward(input, in_shape, output, out_shape, num_cnn active, size_kernel, weight, bias):\n",
    "forward_seq(aAddPaddinf.tolist(), (h_add, w_add),1, out_seq, (h, w), 64,(3,3), cnn.weight, cnn.bias)\n",
    "seq_end = time.time()\n",
    "time_run.loc['Convolution','seq_pure'] = seq_end - seq_start\n",
    "error.loc['Convolution','seq_pure'] = np.sum(abs(output - out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_paral_jit = np.empty((cnn.numKernel, h*w), dtype=float)\n",
    "jit_p_start = time.time()\n",
    "#CNN_forward(input, in_shape, output, out_shape, num_cnn active, size_kernel, weight, bias):\n",
    "forward(aAddPaddinf, (h_add, w_add), 1,output_paral_jit, (h, w), 64, (3,3), cnn.weight, cnn.bias)\n",
    "jit_p_end = time.time()\n",
    "time_run.loc['Convolution','jit'] = jit_p_end - jit_p_start\n",
    "error.loc['Convolution','jit'] = np.sum(abs(output - output_paral_jit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "output_paral = np.empty((cnn.numKernel, h*w), dtype=float)\n",
    "block_size = (16, 16)\n",
    "# print(f'({shape_out.h // block_size[0] + 1}, {shape_out.w // block_size[1] + 1})')\n",
    "# grid_h, grid_w = shape_out.h // block_size[0] + 1,shape_out.w // block_size[1] + 1\n",
    "# grid_size = (grid_h, grid_w)\n",
    "grid_size = (math.ceil(h / block_size[0]),\n",
    "             math.ceil(w / block_size[1]))\n",
    "# print(grid_size)\n",
    "p_start = time.time()\n",
    "#CNN_forward(input, in_shape, output, out_shape, num_cnn active, size_kernel, weight, bias):\n",
    "CNN_forward[grid_size, block_size](aAddPaddinf, (h_add, w_add), 1, output_paral, (h, w), 64 ,(3,3), cnn.weight, cnn.bias)\n",
    "p_end = time.time()\n",
    "time_run.loc['Convolution','cuda.jit'] = p_end - p_start\n",
    "error.loc['Convolution','cuda.jit'] = np.sum(abs(output - output_paral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_pure</th>\n",
       "      <th>seq_lib</th>\n",
       "      <th>jit</th>\n",
       "      <th>cuda.jit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Convolution</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            seq_pure seq_lib  jit cuda.jit\n",
       "maxpool          0.0       -  0.0      0.0\n",
       "Convolution      0.0       -  0.0      0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_pure</th>\n",
       "      <th>seq_lib</th>\n",
       "      <th>jit</th>\n",
       "      <th>cuda.jit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpool</th>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.278227</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Convolution</th>\n",
       "      <td>6.111412</td>\n",
       "      <td>2.462196</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.009995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seq_pure   seq_lib       jit  cuda.jit\n",
       "maxpool      0.003003  0.006003  0.278227  0.002002\n",
       "Convolution  6.111412  2.462196  0.004997  0.009995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cấu trúc mô hình: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 256 ,(w * h)) \n",
    "w = 128\n",
    "h = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_1 = Convolution(64, Shape(3,3))\n",
    "maxpool_1 = Maxpool(64, Shape(2,2))\n",
    "con_2 = Convolution(128,Shape(3,3))\n",
    "maxpool_2 = Maxpool(128, Shape(2,2))\n",
    "con_3 = Convolution(256,Shape(3,3))\n",
    "con_4 = Convolution(256,Shape(3,3))\n",
    "maxpool_3 = Maxpool(256, Shape(2,2))\n",
    "con_5 = Convolution(512,Shape(3,3))\n",
    "\n",
    "input = a.reshape((1,w*h))\n",
    "\n",
    "start = time.time()\n",
    "out_conv1 = con_1.forward(con_1.addPadding(input, (32,128), 1), (32,128), 1, 'relu')\n",
    "out_pooling1, out_shape = maxpool_1.forward_sequential(out_conv1,Shape(32,128))\n",
    "out_conv2 = con_2.forward(con_2.addPadding(out_pooling1, out_shape, 64), (16,64), 64, 'relu')\n",
    "out_pooling2, out_shape = maxpool_2.forward_sequential(out_conv2,Shape(16,64))\n",
    "out_conv3 = con_3.forward(con_3.addPadding(out_pooling2,out_shape,128), out_shape, maxpool_2.numKernel, 'relu')\n",
    "out_conv4 = con_4.forward(con_4.addPadding(out_conv3, out_shape, 256),(8,32), 256,'relu')\n",
    "out_pooling3, out_shape = maxpool_3.forward_sequential(out_conv4,Shape(8,32))\n",
    "out_conv5 = con_5.forward(con_5.addPadding(out_pooling3,out_shape, maxpool_3.numKernel), (4,16), 256,'relu')\n",
    "end = time.time()\n",
    "time_run.loc[\"CNN\",'seq_lib'] = (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\nagin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "block_size = (16, 16)\n",
    "grid_size = (math.ceil(h / block_size[0]),\n",
    "            math.ceil(w / block_size[1]))\n",
    "p_out_conv1 = np.empty((con_1.numKernel, 32*128),dtype=float)\n",
    "p_out_conv2 = np.empty((con_2.numKernel, 16*64),dtype=float)\n",
    "p_out_conv3 = np.empty((con_3.numKernel, 8*32),dtype=float)\n",
    "p_out_conv4 = np.empty((con_4.numKernel, 8*32),dtype=float)\n",
    "p_out_conv5 = np.empty((con_5.numKernel, 4*16),dtype=float)\n",
    "p_maxpool_1 = np.empty((con_1.numKernel, 16*64),dtype=float)\n",
    "p_maxpool_2 = np.empty((con_2.numKernel, 8*32),dtype=float)\n",
    "p_maxpool_3 = np.empty((con_4.numKernel, 4*16),dtype=float)\n",
    "\n",
    "para_s_time = time.time()\n",
    "CNN_forward[grid_size, block_size](cuda.to_device(con_1.addPadding(input,(32,128),1)),(32 + con_1.padding*2, 128+ con_1.padding*2), 1, \n",
    "                                                p_out_conv1, (32, 128), 64 ,(3,3), con_1.weight, con_1.bias)\n",
    "\n",
    "forward_paralle[grid_size, block_size](cuda.to_device(p_out_conv1), (32, 128), p_maxpool_1, (16, 64), (2,2), 64)\n",
    "\n",
    "CNN_forward[grid_size, block_size](cuda.to_device(con_2.addPadding(p_maxpool_1,(16, 64),64)),(16 + con_2.padding*2, 64+ con_2.padding*2), 64, \n",
    "                                                p_out_conv2, (16, 64), 128 ,(3,3), con_2.weight, con_2.bias)\n",
    "\n",
    "forward_paralle[grid_size, block_size](cuda.to_device(p_out_conv2), (16, 64), p_maxpool_2, (8, 32), (2,2), 128)\n",
    "\n",
    "CNN_forward[grid_size, block_size](cuda.to_device(con_3.addPadding(p_maxpool_2,(8, 32),128)),(8 + con_3.padding*2, 32+ con_3.padding*2), 128, \n",
    "                                                p_out_conv3, (8, 32), 256 ,(3,3), con_3.weight, con_3.bias)\n",
    "\n",
    "CNN_forward[grid_size, block_size](cuda.to_device(con_4.addPadding(p_out_conv3,(8, 32),256)),(8 + con_4.padding*2, 32+ con_4.padding*2), 256, \n",
    "                                                p_out_conv4, (8, 32), 256 ,(3,3), con_4.weight, con_4.bias)\n",
    "\n",
    "forward_paralle[grid_size, block_size](cuda.to_device(p_out_conv4), (8, 32), p_maxpool_3, (4, 16), (2,2), 256)\n",
    "\n",
    "CNN_forward[grid_size, block_size](cuda.to_device(con_5.addPadding(p_maxpool_3,(4, 16),256)),(4 + con_5.padding*2, 16+ con_5.padding*2), 256, \n",
    "                                                p_out_conv5, (4, 16), 512 ,(3,3), con_5.weight, con_5.bias)\n",
    "para_e_time = time.time()\n",
    "time_run.loc[\"CNN\",'cuda.jit'] = (para_e_time - para_s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.mean(np.abs(p_out_conv1 - out_conv1)) == 0.000\n",
    "assert np.mean(np.abs(p_maxpool_1 - out_pooling1)) == 0.000\n",
    "assert np.mean(np.abs(p_out_conv2 - out_conv2)) == 0.000\n",
    "assert np.mean(np.abs(p_maxpool_2 - out_pooling2)) == 0.00\n",
    "assert np.mean(np.abs(p_out_conv3 - out_conv3)) == 0.00\n",
    "assert np.mean(np.abs(p_out_conv4 - out_conv4)) == 0.00\n",
    "assert np.mean(np.abs(p_maxpool_2 - out_pooling2))==0.00\n",
    "assert np.mean(np.abs(p_out_conv5 - out_conv5))==0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_pure</th>\n",
       "      <th>seq_lib</th>\n",
       "      <th>jit</th>\n",
       "      <th>cuda.jit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpool</th>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.278227</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Convolution</th>\n",
       "      <td>6.111412</td>\n",
       "      <td>2.462196</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>319.406635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seq_pure     seq_lib       jit  cuda.jit\n",
       "maxpool      0.003003    0.006003  0.278227  0.002002\n",
       "Convolution  6.111412    2.462196  0.004997  0.009995\n",
       "CNN               NaN  319.406635       NaN  0.973556"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_pure</th>\n",
       "      <th>seq_lib</th>\n",
       "      <th>jit</th>\n",
       "      <th>cuda.jit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxpool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Convolution</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            seq_pure seq_lib  jit cuda.jit\n",
       "maxpool          0.0       -  0.0      0.0\n",
       "Convolution      0.0       -  0.0      0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
